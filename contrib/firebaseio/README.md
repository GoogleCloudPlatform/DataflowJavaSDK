## FirebaseIO for Dataflow

This library includes two components for communicating with [Firebase](https://www.firebase.com/) from Dataflow:

* `FirebaseSource` an `UnboundedSource` which can watch a Firebase ref for events and attempts (but does not guarantee) to deliver those events in order to the Dataflow pipeline. The source will unmarshal `DataSnapshot`s generated by these events into the paramaterized type specified by your `FirebaseSource`, which can be any object serializable by Jackson.

* Various `FirebaseDoFn` which can be used to write data to a firebase:
  * `DoFirebasePush` will attach unique and time-ordered strings as keys to objects recieved from the pipeline.
  * `DoFirebaseSet` will overriding data at the key's location with the specified `Object`
  * `DoFirebaseUpdate` will update the tree at the ref with the given `Map<String, Object>`


These utilities also use various `FirebaseEvents` to wrap your unmarshalled data in a Jackson Serializable POJO, which retains event type information. So for example you could filter a pipeline on `ChildAdded<T>` events, where your original `DataSnapshot` was unmarshalled into a Jackson Serializable POJO of type `T`.

The library uses the firebase JVM client library and as such takes advantage of Web sockets for data transfer. However this means that writing to Firebase will use one websocket per shard, so if you plan to fan out your writes, make sure to limit the parallelism with `PTransform#withMaxParallelism` to avoid capping out your available connections.
